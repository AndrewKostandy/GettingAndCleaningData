# README.md

#### Below is the list of files, their location and content description:

###### 1. README.md <br />
Location: Repository <br />
Content: The list of files submitted and the instruction list with the description of how the run_analysis.R script works. <br /><br />

###### 2. CodeBook.md <br />
Location: Repository <br />
Content: The description of the variables in tidy_data.txt and Study Design & Licensing information <br /><br />

###### 3. run_analysis.R <br />

Location: Repository <br />
Content: The R script that reads the input data, manipulates it and generates the tidy_data.txt file as output. <br /><br />

###### 4. tidy_data.txt <br />

Location: Submitted on Coursera <br />
Content: The output file generated by running the run_analysis.R script. For more info, see CodeBook.md <br /><br />

#### The following steps are needed to read the tidy_data.txt file and view it in R: <br />

1. Download the tidy_data.txt file from my repository. <br />
2. Type the following code in R and insert the location where you downloaded the file to. <br />
tidyData<-read.table("InsertFileLocationAndNameHere", header = TRUE)  <br />
View(tidyData) <br />

#### Instructions to run the script successfully

As per the project instructions, running this script requires the Samsung Data Set Folder called UCI HAR Dataset to be located inside your working directory and to have it's internal folder structure and file names unchanged. <br /> <br />
This Folder contains the input that the run_analysis.R script needs to run to create the output file. <br />
The Output file generated is called tidy_data.txt and will be created inside your working directory.<br />
Running this script requires you to have the dplyr package installed.<br />

##### Below is a detailed description of what the script does: <br />

1. Reading Features from features.txt <br /><br />
2. Reading Activity Labels from activity_labels.txt <br /><br />
3. Reading All Test Data & then merge them at the final step. <br />
  a. Reading subject_test Data. Renaming Column Name to subject. <br />
  b. Reading y_test data which contains activity numbers. Renaming Column Name to activity. <br />
  c. Reading X_test data. Renaming Column Names to values read earlier from features.txt       
  d. Merging all the test data together. <br /><br />
4. Reading All Train Data & then merge them at the final step. <br />
  a. Reading subject_train Data. Renaming Column Name to subject. <br />
  b. Reading y_train data which contains activity numbers. Renaming Column Name to activity. <br />
  c. Reading X_train data. Renaming Column Names to values read earlier from features.txt <br />
  d. Merging all the train data together. <br /><br />
5. Merging alltestdata and alltraindata into alldata. <br /><br />
6. Removing Duplicate Column names. <br /><br />
7. Extracting only the measurements on the mean and standard deviation for each measurement. I chose to select all columns containing mean() or std() which includes for each of the x,y,z axis. I chose these because those are the main measurements. I also selected the subject and activity columns obviously. <br /><br />
8. Clearly labeling activities variables replacing the numbers 1-6 with the respective activity name which was read earlier from activity_labels.txt <br /><br />
9. Creating a new data set tidy_data with the with the average of each variable for each activity and each subject. <br /><br />
10. Making Column Names lower case and more descriptive by showing that they are averages (adding avg at the end) and removing brackets and dashes from the Column Names that change to dots when writing to and then reading from file. This is as per best practices that state that variable names should all be lower case when possible, be descriptive, and not have dots or white spaces.<br /><br />
11. Writing the data set into a file tidy_data.txt. This file is written into your working directory. <br /><br />
